<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Program on Fuyi Atlas</title>
    <link>https://fuyi-atlas.github.io/categories/program/</link>
    <description>Recent content in Program on Fuyi Atlas</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 24 Jun 2024 21:16:17 +0800</lastBuildDate>
    <atom:link href="https://fuyi-atlas.github.io/categories/program/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Geo Atlas，用于构建矢量切片服务的Java基础库</title>
      <link>https://fuyi-atlas.github.io/posts/program/geo-atlas/001/</link>
      <pubDate>Mon, 24 Jun 2024 21:16:17 +0800</pubDate>
      <guid>https://fuyi-atlas.github.io/posts/program/geo-atlas/001/</guid>
      <description>Geo Atlas 是什么？ Geo Atlas，译为地理地图册(地理地图集)，就像小时候买到的纸质的地理地图册书本，里面填充着各式各样的地图。所以, 我也希望有那么一个东西，同样可以对外提供各种各样的地图以供使用。
目前来说，他还只是一个基于Java的开发的，可用于快速构建矢量切片服务的基础库。
本例中基于Geo Atlas实现了一个精简版本的矢量切片服务，从结果来看，可以将其看作为仅实现了矢量切片功能的GeoServer的精简提升版本。
背景与动机 首先，我是一个主做服务端开发的GIS开发工程师，平时接触最多的就是管网地图服务发布。此前的工作中没有使用任何平台技术，比如：ArcGIS、超图等，而是使用开源技术。技术栈大体可以总结为：SpringBoot + GeoServer + Mapbox + 空间数据库。
其次，目前在业务应用上，二维地图还是主流。而二维地图技术里面，属Mapbox Vector Tile的体验最好。所以，目前的技术路线是通过 GeoServer 来发布Vector Tile。
然后，在 GeoServer 使用中，我发现了这个几个问题：
受限于其开源协议（GPL 2.0）的约束，你无法通过修改部分源代码的方式，将其直接集成到系统内部。只能是单独部署，通过其提供的REST接口进行交互。基于此，部署方式同样受限。 GeoServer 是一个大而全的东西，同时他是一个单体项目。也就是说，哪怕我只需要提供MWTS+MVT服务，我也需要部署一个全功能的节点，无法按需使用（这里不得不提一下GeoServer Cloud项目，但是它提出得要求更多了，需要一套微服务的环境） 从公谨《WebGIS数据不切片或是时代必然》一文推论，GeoServer中提供的MVT技术（指数据切片过程）已经算是切片起源时代的产物了，而今已经跨过了矢量切片时代（数据还是预切），进入了动态矢量切片时代了 GeoServer中Vector Tile与GeoWebcache中的Tile Meta技术有冲突，瓦片清理存在BUG。可以理解为，GeoServer对于矢量瓦片的支持并不是很好。 不能很好的处理瓦片缓存与动态业务数据的矛盾，即使GeoWebcache提供缓存清理的策略。（Layer中Boundingbox范围问题） GeoServer完全是栅格金字塔技术的实现，不过是将栅格金字塔技术同时应用在栅格数据和矢量数据上，同时他并没有很好的针对不同层级对数据进行抽稀简化（其尝试从服务端配图SLD中获取数据分级规则，我没有测试过，但反对，理由参见: 关于矢量瓦片技术支持前端渲染带来的思考），那么就出现了一个pbf有近20M的情况。同时也回答了为什么现在大家都直接在数据库层面实现矢量瓦片（或者说是在数据源中），一是可以无视数据传递的时间损耗；二是可以直接做抽稀简化，这样出去的数据少了，传输速度自然也快了；三是数据库空间支持已经很成熟了；四是门槛高啊（护城河）
最后，我也想对我目前的状态做一次总结。那么，Geo Atlas应该就是我最好的总结方式。因为它既可以丰富我的简历🫣，又可以帮助我绘制技能树，完成这一次的总结。
ps: 当然，还有当下信创的背景原因。就当，抛砖引玉了😧，哈哈哈😬
特性 遵循 OGC Two Dimensional Tile Matrix Set and Tile Set Metadata Standard 2.0 [并不完全遵循] 尝试遵循 NEW OGC API 提供矢量切片能力 支持自定义数据属性分级规则 支持Google瓦片坐标系(原点在左上角, 默认即为Google瓦片坐标系) 支持3857(900913), 4490投影(即默认提供相应的TileMatrixSet) 支持自定义坐标系及自定义坐标转换行为(源数据坐标系) 支持自定义数据范围(OGC TileMatrixSet Limits，拒绝范围外请求) 提供全局统一的，可快速集成的瓦片缓存组件， 支持基于内存和文件系统的缓存 支持使用GeoPackage进行缓存 支持Seed, Reseed, Truncate三种瓦片缓存处理策略 提供Namespace, Datastore, FeatureLayer元数据管理模块，并提供一个可视化操作界面(Geo Atlas Dashboard) 提供栅格数据切片能力 提供地形数据切片能力 提供按需快速集成能力(将常用功能封装为各种stater) 截图 快速开始 以下说明旨在基于Docker技术快速搭建一个矢量切片服务示例。</description>
    </item>
    <item>
      <title>微天气 终篇</title>
      <link>https://fuyi-atlas.github.io/posts/program/micro-weather/009/</link>
      <pubDate>Thu, 14 Mar 2024 13:31:12 +0800</pubDate>
      <guid>https://fuyi-atlas.github.io/posts/program/micro-weather/009/</guid>
      <description>起源 天气小程序产生于2022年年初，目的是用于验证自己是否有进入全栈开发（仅前后端）的能力。
受新冠疫情影响，2022年的春节是在杭州过的。还记得当时附近好几个地方都被划为了高风险，对整个区进行了管控。如果选择回家的话，得到将是14天的隔离，还不确定能否回来上班。因此便没有回去了。好在所在的区域情况并没有那么的严重，还是可以去买菜的。领了消费券，再加上公司发的年货，也没有想象中的那么糟糕。
所以，既然没有回去，又有十来天的时间，总得做点什么东西才行，对吧 🙄！
2022年，是我工作的第四个年头。受多方面的信息影响，我也想看看验证自己是否有进入全栈开发（仅前后端）的能力。
历程 拂衣天气，又名微天气。
一个集地理信息与天气预报为一体的天气预报类小程序，界面精美，使用便捷。【致敬：和风天气】！
💡 主要是有人给我说拂衣天气，听着还以为是卖衣服的。so，我就想着换个名字，就有了微天气。但是由于微信认证的原因，所以有些地方还是拂衣天气。现在细细想来，好像也没有什么关系，那就先这样吧 🙄
该项目从2022年1月12号正式启动，于2022年3月19日发布一阶段最终版本（1.1.9），总体耗时2个月零7天。从内容完整度以及界面友好程度来说，我给自己70分。 此前实在是没有经验，也没有相关的习惯，天气小程序开发过程中并没有编写相关的文档。所以在小程序开发完成之后，本来计划是将拂衣天气完整的开发过程通过文章的方式记录下来，并将该项目开源出去，甚至还想将该项目提交给和风天气。但最后的结果就是：文章就完成了四篇，也就是一个开头，没啥实际内容。@time 2022年8月16日 好的，现在时间来到2023年12月，我又有点时间了，因为我离职了（不是被裁）。这次的目标是完善文档，修复发现的一些BUG，然后新增一些内容，最终将该小程序开源，并贡献给和风天气。 接下来，让我来回忆一下每个阶段的详细内容 🤔
项目初始 为什么会想到做一个天气小程序呢？
嗯，首先我是一个做服务端开发的GIS开发工程师。在当时刚结束一个小程序的开发工作，觉得小程序这个东西还挺有意思。同时受到周边各种信息的影响，也想试一试写点前端的内容，最好是可以方便发布的那种，也算是自己的作品不是。为什么会选择天气类别，好像是当时刷网页还是什么，看到一个人分享自己做了一个天气机器人，然后给女朋友推天气信息。so， 🫣
所以，我当时就想做一个天气类别的小程序，以此进行全栈开发能力的试炼。我想这会是一个微信小程序、是一个可以正常使用的小程序，以Java进行服务端开发，以Mapbox实现天气数据可视化。
本阶段事务分为了三个阶段，分别是：调研、学习、实现
调研 天气小程序什么最重要？当然是天气数据最为重要，所以首要内容便是确定天气数据的来源。其次便是确定本次天气小程序的技术实现构成。
天气数据
天气数据需要是真实的、可用的。那么可以通过网络中提供的天气API进行获取。
通过一定的检索后，我选定了两个天气平台，分别是：和风天气、心知天气。
高德天气：大平台，但是目前服务类目比较少
彩云天气：免费接口几乎没有，收费又太贵
心知天气
心知天气试用版与开发者版开发产品几乎等同，且开发者版收费也不贵。最为关键的是，支持以经纬度方式进行天气查询。
和风天气
几乎可以免费使用其提供的所有 API，且同样支持经纬度方式进行天气查询。
对比了这两者，发现至少都需要注册为开发者之后，才可以较好的使用其服务。且两者的开发者认证均需要实名。
关于天气API的选择，我最终选择了和风天气，倒不是因为它可以免费使用。其实，刚开始的时候我更倾向于使用心知天气，因为它还可以直接查昨天的天气（和风对于历史天气的查询比较麻烦）。但是和风天气首页结合了地图进行可视化，而且还提供有APP可以使用（方便参考）。再加上，我想了想，其实我并没有迫切的需要知道昨天的天气情况。 🙄
💡 其实最重要的原因在于：我先注册了心知天气（需要审核），过了半天后再去注册了和风天气（需要审核），但是最先通过审核的是和风天气（耗时大概也就半天左右，我是在春节期间注册的啊）。
技术实现构成
这里存在一个遗憾，小程序原生并不支持使用如mapbox这样的第三方地图框架，初始想法是通过webview的方式使用mapbox，但是遗憾的是，webview并不对个人类型的小程序开放使用。
所以，退而求其次，选择腾讯地图（及其提供的样式）实现地图浏览。
服务端程序则使用Java语言开发，天气数据是经过服务端代理的方式形成内部的数据接口，并非是小程序直接调用和风的接口
最终将服务端程序部署到阿里云
学习 我是一个后端开发工程师，我不怎么会写页面，我特别的讨厌写CSS。我也没有接触过前端开发和微信小程序开发，所以需要提前储备一下相关知识。
前端知识
我并没有想要精通前端技术，但是我需要比较体系的了解一下前端技术，方便进行小程序开发。所以我在B站找了两门前端视频学习（粗略的刷了一遍）
尚硅谷Web前端零基础入门HTML5+CSS3基础教程丨初学者从入门到精通 千锋web前端开发项目教程_1000集完全零基础入门HTML5+CSS3+JS到精通 微信小程序知识
其实就看官方文档就足够了，不过心虚的我还是在极客时间找了门课。最终发现：就官方文档就足够了，因为我并不需要很深入的东西
实现 在有一定准备后，就开始进入实现环节了。
在这里有一个大问题就是UI设计问题，我看和风天气APP就挺好看的，有天气有地图，身为GIS开发的我就很喜欢。又发现无论是和风天气官方，还是其他天气小程序应用，基本都没有携带地图的。
所以，我当即决定参考和风天气官方APP界面，做一个类似的天气小程序。当然，我做的这个小程序就是奔着开源，同时将作为作品分享给和风天气，才想着如此操作的。请务必慎重 🤔
在经过简单的设计过后，于2022年1月18日正式进行开发，2022年3月19日发布一阶段最终版本1.1.9。
文档补充 今天偷的懒，明天都会让你加倍还回来。此前一是没意识，二是认为没必要，三还是太懒，所以并没有同步编写文档。
现在计划将拂衣天气开发的完整过程通过文章的方式记录下来，下面是我对该整体内容的编写计划：
但是，我又要开始说但是了。打工人还是打工人！
天气小程序于2022年4月前就已经完成了开发，直至到今天（2022年8月16日）也就才完成了三篇文章，不得不说拖延症是真的严重。天气小程序只是一个应用，就目前的投入收益来说，不应该把过多的时间放在小程序上面。在加上距离开发已经过去了4个月，开发之时并没有进行文档产出，所以现在才进行复盘则是相当于重新实现了一遍。就目前来看，核心的行政区划数据合并已基本完成，所以，后面将暂停小程序相关内容，变更为GIS基础与计算机基础的学习。
💡 对的，停更说明。
死灰复燃 打工是不可能打工的，只要我不打工，我就有时间了 🙄</description>
    </item>
    <item>
      <title>微天气 小程序发布记录</title>
      <link>https://fuyi-atlas.github.io/posts/program/micro-weather/008/</link>
      <pubDate>Wed, 13 Mar 2024 22:02:53 +0800</pubDate>
      <guid>https://fuyi-atlas.github.io/posts/program/micro-weather/008/</guid>
      <description>前言 服务端部署：由于并没有建立全链路的自动化部署，目前还需要到云服务器上进行环境制作（数据库，Nginx），并拉取后端服务进行部署 小程序发布：需要先完成服务端部署，保证应用正常可用 服务端部署 数据库安装与数据初始化 最开始的时候，我是直接将在操作系统上面安装数据库，后面发现迁移的时候还是不方便，即使我可以放弃数据库中的数据，但是还是需要重新创建数据表结构。
所以，在这一次中，我编写了一个Dockerfile脚本，使用一个空数据库作为模板，构建了postgis镜像。基于此，我可以实现快速的迁移与部署。由于这是一个实验性质的小程序，所以数据资产并不是十分重要（并不是说不安全，而是我可以丢弃），所以我可以安心的使用docker技术。在初始化postgis容器的时候，会同步释放模板以创建数据库。这将会带来一个问题是：如果重新创建容器，那么将会得到一个全新的数据库。当然你可以把数据库的data目录映射到宿主机上，应该可以解决这个问题。
docker build -t registry.cn-hangzhou.aliyuncs.com/fuyi-atlas/micro-weather-postgis:12-3.4 . 最后，我在本地完成该镜像的制作后，将其推送到我的阿里云镜像仓库中，便于后续使用。你可以注册一个阿里云账户去免费启用个人版的镜像仓库，也可以直接使用dockerhub。
docker push registry.cn-hangzhou.aliyuncs.com/fuyi-atlas/micro-weather-postgis:latest 应用部署 于本地完成镜像制作，并推送到阿里云镜像仓库中。
为了更方便的进行部署，我编写了docker compose脚本，用于将数据库与应用服务端程序一并启动。目前程序中有一个海报分享的功能，该功能实现中需要一些额外的中文字体的支持，所以需要将此部分中文字体放置到宿主机的某个目录下，并在环境变量中指定该目录，脚本中会将该目录映射该到容器内的/usr/share/fonts目录下
对于图片访问，还是延续此前的实现，即在服务器端生成分享海报，存储到本地（指服务器磁盘），而后通过Nginx代理访问。由于目前的服务器我是与他人共用，同时还需要配置域名证书，所以暂时没有将Nginx的部署同步放置到docker compose脚本中。
💡 由于部署中需要提供部分敏感信息，比如：小程序的密钥、天气应用的key、docker镜像仓库地址。我将所有信息以环境变量的方式进行占位，通过docker compose的环境变量进行替换，即.env文件
小程序发布 小程序端的发布就比较简单了
先将base_url更换为正式环境的地址（我没有提交此部分代码，你可以自己更改） 本次调试没有问题后，就可以上传代码，即提交为体验版本 而后使用体验版本测试没有问题，就可以提交审核 审核通过后，就可以发布了 总体来看，本次发布很顺利，审核在十分钟就通过了。</description>
    </item>
    <item>
      <title>微天气 Github Action镜像自动构建与推送</title>
      <link>https://fuyi-atlas.github.io/posts/program/micro-weather/007/</link>
      <pubDate>Wed, 13 Mar 2024 16:14:48 +0800</pubDate>
      <guid>https://fuyi-atlas.github.io/posts/program/micro-weather/007/</guid>
      <description>前言 这里暂不作过多的操作，还是保持与此前一致。即通过Github Action完成Docker Image的build与push，目标仓库为阿里云容器镜像服务实例（个人版）registry.cn-hangzhou.aliyuncs.com
那么一共分为三个部分：
Dockerfile编写 阿里云容器镜像服务配置 Github Action Dockerfile编写 jdk17 gradle FROM gradle:jdk17-alpine AS build # 设置语言，支持中文 ENV LANG C.UTF-8 COPY --chown=gradle:gradle . /opt/gradle/src WORKDIR /opt/gradle/src RUN gradle clean build -x test --no-daemon FROM eclipse-temurin:17-jdk-jammy COPY --from=build /opt/gradle/src/build/libs/*.jar /usr/app/ WORKDIR /usr/app/ RUN sh -c &amp;#39;touch micro-weather-backend-1.0.0-RELEASE.jar&amp;#39; ENTRYPOINT [&amp;#34;java&amp;#34;, &amp;#34;-jar&amp;#34;, &amp;#34;micro-weather-backend-1.0.0-RELEASE.jar&amp;#34;] Github Action 先在阿里云镜像服务中创建命名空间
创建仓库（可选，因为可以自动创建）
编写Github Action脚本
name: Micro Weather Service Image Build And Push CI on: push: branches: - &amp;#39;main&amp;#39; jobs: docker: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v2 # setup-qemu 如果您想使用 QEMU 添加仿真支持以便能够针对更多平台进行构建，则 action 会很有用 - name: Set up QEMU uses: docker/setup-qemu-action@v1 # setup-buildx-action 将默认使用docker-container 构建器驱动程序创建和引导构建器。非必需 - name: Set up Docker Buildx uses: docker/setup-buildx-action@v1 - name: Login to Aliyun DockerHub uses: docker/login-action@v1 with: registry: ${{secrets.</description>
    </item>
    <item>
      <title>微天气—行政区划数据（二）</title>
      <link>https://fuyi-atlas.github.io/posts/program/micro-weather/006/</link>
      <pubDate>Mon, 16 Oct 2023 21:38:32 +0800</pubDate>
      <guid>https://fuyi-atlas.github.io/posts/program/micro-weather/006/</guid>
      <description>前言 此前提到微天气应用程序需要使用到行政区划数据，不过上一章所使用的数据来源于网络，或多或少都可以考虑一下是否还有其他获取的方式，所以也就有了本文的内容。
在这里，将基于全国1:100万基础地理信息数据进行行政区划数据的提取。本文用于记录使用程序实现全国1:100万基础地理信息数据合并的全过程。
当然，本文产生的最重要原因其实并不是受到微天气的启发，更多的是个人想试一试能不能用。
数据说明 全国1：100万公众版基础地理信息数据（2021）覆盖全国陆地范围和包括台湾岛、海南岛、钓鱼岛、南海诸岛在内的主要岛屿及其临近海域，共77幅1:100万图幅，该数据集整体现势性为2019年。数据采用2000国家大地坐标系，1985国家高程基准，经纬度坐标。
为满足广大社会群众对地理信息数据资源的需求，经自然资源部授权，全国地理信息资源目录服务系统提供全国1:100万全图层要素免费下载的服务。下载数据采用1：100万标准图幅分发，内容包括水系、居民地及设施、交通、管线、境界与政区、地貌与土质、植被、地名及注记9个数据集，且保存要素间空间关系和相关属性信息。
💡 提供下载的是矢量数据，不是最终地图，与符号化后的地图再可视化表达上存在一定差异。用户利用此数据编制地图，应当严格执行《地图管理条例》有关规定；编制的地图如需向社会公开的，还应当依法履行地图审核程序。
成果规格 分幅编号及范围
1：100万公众版基础地理信息数据（2021）的图幅总数为77幅，分幅数据按照GB/T 13989-2012《国家基本比例尺地形图分幅和编号》执行。空间存储单元为6°（经差）×4°（纬差）。
坐标系统
平面坐标系： 2000国家大地坐标系。 高程基准：1985国家高程基准。 地图投影：分幅数据采用地理坐标，坐标单位为度。 几何精度
更新后地物点对于附近野外控制点的平面位置和高程中误差符合下表的要求，以两倍中误差值为最大误差。
地物点误差 最小 最大 平面位置 100 500 高程 50 200 现势性
1:100万地形数据现势性与更新使用的数据源的现势性一致，数据整体现势性达到2019年。
成果数据组织 全国1：100万公众版地形数据（2021）内容包括水系、居民地及设施、交通、管线、境界与政区、地貌与土质、植被、地名及注记9个数据集。
数据分层的命名采用四个字符，第一个字符代表数据分类，第二三个字符是数据内容的缩写，第四个字符代表几何类型。
目标 实现分图层合并（处理图幅合并时接边问题） 水系（暂缓） 交通（暂缓） 境界与政区（国、省、市、县） 地名及注记 根据合并后的行政区划与地名注记，制作行政区划数据库 数据库使用PostgreSQL（PostGIS） 设计 图层解析程序 Java程序， 使用GDAL 读取GDB
逻辑 根据《国家基本比例尺地形图分幅和编号》规定可知网格范围，通过网格范围动态生成对应网格的分幅编号，并以该编号进行数据检索。如果命中则根据成果数据组织规格以及相关标准对数据进行解析，如果未命中则跳过，直至网格扫描完毕。
经度：72~138（E），43~53（11） 纬度：0~56（N），A~N（14） 即，网格范围:[43,53] x [A,N] 数据的处理流程可使用责任链模式进行，后续也方便加入其他的处理流程。即，整体的执行框架为策略模式+责任链模式。为统一策略选择模型，在此提出图层定义（LayerDefinition）的概念。
LayerDefinition由如下几个关键要素组成：
图层数据源（LayerSource） driver：驱动，参考java.sql.UnWrapper实现 instance name catalog： schema： table： commonDefinitionKey ：常规定义缓存的key fieldDefinitionKey ：字段定义缓存的key featureCarrierKey ：要素载体缓存的key origin：数据来源（分幅文件路径） scale：比例尺（如：1000000，表示1:1000000） sourceSpatialRef：源坐标系（表现形式可为标准ID、PROJ Text、WKT Text） sinkSpatialRef：目标坐标系（表现形式可为标准ID、PROJ Text、WKT Text） featureCode：要素分类码，对应成果数据组织中的要素分类（如：C、B） name：图层命名，也是图层分类码 layerCode：图层分类码 release：释放格式（比如：WMTS、Shapefile、GDB…） 描述字符为：比例尺:源坐标系:目标坐标系:要素分类码:图层名称:释放格式，在描述字符串中，坐标系仅使用标准ID表示</description>
    </item>
    <item>
      <title>微天气—行政区划数据（一）</title>
      <link>https://fuyi-atlas.github.io/posts/program/micro-weather/005/</link>
      <pubDate>Tue, 10 Oct 2023 21:21:32 +0800</pubDate>
      <guid>https://fuyi-atlas.github.io/posts/program/micro-weather/005/</guid>
      <description>前言 微天气程序中存在如下几个功能需要使用到行政区划数据：
城市列表，需要支持城市搜索 根据经纬度获区域（城市）的天气数据 地图坐标拾取并获取所处区域（城市）信息，同时获取天气数据 对于城市的天气数据，不使用和风天气的城市列表，而是自行维护，通过空间位置（经纬度）进行关联。对于城市位置的定义，本可以选择如行政中心或市中心，但我没有这样的数据，就直接用城市区划范围的中心点代替。不准确不重要，过程已经满足了，且后续是可以替换的。
其实完全可以使用官方提供的城市数据和GeoAPI覆盖这些功能，但既然我是做GIS开发的，而且手里也有可以用作研究学习的数据，为啥不用呢。
今天突然发现，其实我可以爬一下和风的数据，这样就可以拿到城市选择的经纬度数据了 @time 2023.10.10
About 行政区划解析程序，输入shape文件，写入Postgresql.
大体完整的四级行政区划数据组织
github link: fuyi-district-parse
数据情况 数据原源于网络，由于时间久远，我已经忘记了是如何获取到的
名词解释 省级行政区 中国的一级行政区，或称国家一级行政区或省级行政区，是指直属中央政府管辖的行政区划，在历史上曾有不同的称呼。如：省、自治区、直辖市、特别行政区。
地级行政区 地级行政区即“地区级别行政区”，是现行中华人民共和国行政区划中常规的第二级行政区划单位，包括地级市、地区、盟、自治州等。地级行政区隶属于省、自治区、直辖市等省级行政区之下；下辖若干个县、区、县级市、旗等县级行政区。作为特例，东莞市、中山市、嘉峪关市、儋州市等四个地级市下辖街道办事处与乡镇，不辖县、区，因此也称作“直筒子（地级）市”。地级行政区的级别为正厅级，所以非正厅级的省直辖的行政区划不算作地级行政区，例如：湖北省辖的仙桃市、天门市、潜江市；河南省辖的济源市等等。直辖市下辖的区，虽然是正厅级，但未列入地级行政区的统计。
县级行政区 县为中华人民共和国行政区划单位之一，县级行政区指行政地位与“县”相同的行政区划单位的总称，其管辖乡级行政区。为乡、镇的上一级行政区划单位。中华人民共和国成立后，随着行政督察区名称的变更，除各直辖市均隶属于专区（行政督察专区）、地区或地级行政区，现除各直辖市、海南省直管县外均为地级行政区的下一级行政区。
按省、县、乡三级行政区划制度划分，县级行政区属于第二级行政区，为直辖市的下级行政区划单位。 按省、地、县、乡四级行政区划制度划分，县级行政区属于第三级行政区，属于省、自治区所辖地级行政区的下级行政区划单位。 乡级行政区 乡，中华人民共和国现行基层行政区划单位，区划层次介于县与村之间。“乡”为县、县级市下的主要行政区划类型之一。中国行政区划史上，“乡”一直为县的行政区划单元，因此现行处同一层次的区划单位归入乡级行政区。中国自改革开放以来，由于城市的快速扩张，行政区划制度出现了大的变革。1980年代以后“乡改镇”、“乡改街道”的现象越来越普遍。
在乡级行政区划中，乡（包括镇）设有一级人民政府，属于基层政权；乡的行政区划单位为村（含民族村）。但很多乡设有社区，乡的区划单位设置与镇、街道看不出实质性差异。
目的 解析所有数据文件，实现最终入库
使用GeoTools实现
数据库表结构：
行政区划信息（district_info）
id：自增Id（bigserial） name：行政区划名称 grade：行政区划等级（省级行政区：1， 地级行政区：2， 县级行政区：3，） code：行政区代码 center_point：中心点（geometry::point） bounds：行政区边界（geometry） 注：
数据入库前审查，保证行政区代码唯一 使用grade区分省、市、县、乡镇 对于省、市、县code列，统一进行前6位截取（不满6位字符所在数据，直接丢弃），对于乡镇则统一进行前9位进行截取（不满9位字符所在数据，直接丢弃） 省级行政区 存在错乱数据，可以使用行政区代码识别（adcode）
地级行政区 存在错乱数据，可以使用行政区代码识别（code），需要截取前6位
县级行政区 存在错乱数据，可以使用行政区代码识别（code），需要截取前6位
乡级行政区 成果 记录数：46652
点数据为各个行政区中心点
数据表 PostGIS CREATE EXTENSION IF NOT EXISTS postgis WITH SCHEMA public; 行政区划 -- -- Name: district_info_id_seq; Type: SEQUENCE; Schema: public; Owner: postgres -- CREATE SEQUENCE public.</description>
    </item>
    <item>
      <title>如何构建一个矢量瓦片服务</title>
      <link>https://fuyi-atlas.github.io/posts/program/map/how-to-build-a-vector-tile-service/</link>
      <pubDate>Tue, 23 May 2023 22:46:59 +0800</pubDate>
      <guid>https://fuyi-atlas.github.io/posts/program/map/how-to-build-a-vector-tile-service/</guid>
      <description>前言 关于矢量瓦片（节选） 地图瓦片技术是在线地图服务常用的瓦片技术，瓦片就是地图瓦片的具体存储形态，提前切好的瓦片可以大大提高在线地图的访问效率。
栅格瓦片 以图片为介质的栅格瓦片使得在线地图得以迅速普及，优势在于显示效率高、方便传输。但是，随着地图的移动化和应用的逐渐深入，栅格瓦片占用带宽和存储都较大，不利于地图在移动设备的应用。
矢量瓦片 矢量瓦片的产生弥补了栅格瓦片的不足。矢量瓦片数据以矢量形式存在。矢量瓦片体积下，可高度压缩，占用的存储空间比栅格瓦片要小上千倍。数据传输体量小，地图更新的代价小
常见的矢量瓦片制作工具（节选） 目前开源的矢量切片工具还是非常多的，列出一些主流的阐述下：
基于GeoServer的矢量切片插件，适合熟悉GeoServer的用户，操作还比较简单，缺点是切片的行列号与一般的XYZ编号不同不容易单独部署。 基于tippecanoe的矢量切片工具方案，该工具提供了很多高级功能在数据定制化上有很强的优势，但只能部署在Linux，并不是跨平台，只能读取geojson文件，不能直连数据库，不是很好，如果有幸您是c++开发大神，可以改下库的编译绑定平台，使其支持windows，再更改下数据源底层，使其能支持空间数据库，那么该工具会有更多的应用空间。 基于PostGIS的矢量切片方案，该方案在熟悉PostGIS的用户中应该很受欢迎，优势是支持动态矢量切片，有PG社区的系统级加成。 总的来说，工具虽然很多，但是没有一款可以说覆盖一切场景的，具体应用还是看场景的，比如前两个方案都是做底图数据时比较有用，都是静态矢量切片方案，geoserver能直连数据库，tippecanoe有强数据定制性要求，那么如果用户侧重点是简单点的话geoserver够了，用户侧重点是希望对数据做很多高级过滤什么的操作用tippecanoe，但步骤麻烦点。这些矢量切片工具仅仅在处理很久不变的数据，就是切一次用很久的数据，如果数据频繁变化，这种静态数据切片工具就很不好用了。
与其他方案相比，PostGIS方案的好处主要有两大点：
资源开销低：空间数据一般存空间数据库中，传统工具会先从数据库中捞数据，这个数据通常很大，网络开销和服务器端内存都要很大，查询慢计算慢是肯定的。而PostGIS是在数据库中把数据处理完，只把结果传给后台转前台，可以很方便的使用数据库的索引，并行计算等，优化查询和处理速度。 动态矢量切片，数据时效性高：每当根据xyz请求时，数据库会动态查询范围内数据，裁剪简化并输出pbf格式的二进制数据出去，在数据变化频繁的场景下，可以保证用户看到的是最新的数据。 💡 GeoServer、Tippecanoe 皆为静态矢量切片方案，需提前准备切片数据，并进行持久化（GeoServer也可以在使用时进行切片，同时进行持久化）。PostGIS支持动态矢量切片方案，即实时计算生成切片，且不进行切片的持久化。
为什么要自己写一个服务 于我个人而言，我目前仅接触和使用到了GeoServer，且对其中的实现细节并不太清楚，所以想通过参考模仿的方式实现一个示例服务。其次，还想测试在没有如GeoWebcache此类的瓦片缓存的情况下，服务的性能如何。综上所述，其实也就是为了如下这几方面的目的：
学习，了解其中的实现细节
更好的适配
比如说，WMTS服务很明确存在缓存，WMS性能又不够好。如果使用WMTS服务确实可以提升服务的性能，但是对于源数据存在编辑的场景下，缓存问题还是会让人头疼。
那么是否存在动态的矢量瓦片服务？既能解决缓存的问题，同时还没有太大的性能问题。
你或许会提到基于PostGIS的动态矢量瓦片服务，但是有些历史的原因，短时间内没有变法变更数据库。当然也可以基于类如CDC这样的功能进行缓存的更新，但其实还是会存在缓存的问题，只是说可以通过一些手段降低缓存问题出现的概率，并无法从根本上解决问题
所以，基于此，既然PostGIS可以实现动态矢量瓦片服务，我们自然也可以。公瑾大佬曾发文说过，当下地图服务去服务化、数据不切片基本上已经是必然的趋势，那么我为什么还要去做一个服务化的东西。大概就是下面这几个原因了：
数据库技术，在某些特定的因素下，短时间内无法切换到PostGIS 数据量级 性能容忍度 小厂，我不思进取 🙄 后续知识储备 矢量瓦片标准 参见：矢量瓦片标准
在这里贴几个关键点（对于目前使用上来说）：
文件格式
矢量瓦片文件采用Google Protocol Buffers进行编码。Google Protocol Buffers是一种兼容多语言、多平台、易扩展的数据序列化格式。
投影和范围
矢量瓦片表示的是投影在正方形区块上的数据。矢量瓦片不应该包含范围和投影信息。解码方被假定知道矢量瓦片的范围和投影信息。
Web Mercator是默认的投影方式，Google tile scheme是默认的瓦片编号方式。两者一起完成了与任意范围、任意精度的地理区域的一一对应，例如https://example.com/17/65535/43602.mvt。
矢量瓦片可以用来表示任意投影方式、任意瓦片编号方案的数据。
内部结构
图层
每块矢量瓦片应该至少包含一个图层。每个图层应该至少包含一个要素。
几何图形编码
矢量瓦片中的几何数据被定义为屏幕坐标系。瓦片的左上角（显示默认如此）是坐标系的原点。X轴向右为正，Y轴向下为正。几何图形中的坐标必须为整数。
矢量瓦片服务构建 在这里，我选择抄GeoServer的作业。众所周知，PostGIS是开源的，那为什么没有选择抄PostGIS的作业呢？
当下水平不够 想快速验证想法 想基于GeoServer做二次开发，或者说是基于现存的地图服务相关的实现，集各家之大成，合并成一个组在功能上可自由搭配的、较高性能服务端组件 接着说当前的事情。要实现一个动态矢量瓦片服务，我们需要先分析一下实现内容，在此先做出如下拆解：
动态矢量瓦片服务可以理解为没有瓦片缓存的，实时生成的矢量瓦片服务，所以核心还是矢量瓦片服务(@time 20210503: 动态矢量瓦片技术是相对矢量瓦片技术提出的，而矢量瓦片技术的大规模应用还是以预切为主，所以动态矢量瓦片要解决的是不再预切动态生成，同时避免一下子生成大规模瓦片文件的问题) 矢量瓦片服务也就是根据调用端传递的参数，从数据源获取对应的数据，并将其转换为矢量瓦片格式，最终返回给调用端 这里选择瓦片坐标作为检索参数，可以便于服务降级（缓存）和性能优化（瓦片坐标值相对来说更加准确和可固定，且便于降维） 需要实现瓦片坐标系到数据源坐标系下数据范围的相互转换 需要实现数据源的范围查询 需要实现矢量数据到矢量瓦片的编解码 那么大体的实现路径可归结于如下所示：
其中的核心要点总结如下：</description>
    </item>
    <item>
      <title>GeoServer开发环境搭建</title>
      <link>https://fuyi-atlas.github.io/posts/program/geoserver/002/</link>
      <pubDate>Thu, 09 Mar 2023 22:33:44 +0800</pubDate>
      <guid>https://fuyi-atlas.github.io/posts/program/geoserver/002/</guid>
      <description>前言 本文用于记录GeoServer开发环境的搭建过程
通过GeoServer发布计划可以看到，在2.23.x版本开始，会移除对jdk1.8的支持。那么当前我们会选择2.22.x版本进行研究
环境 JAVA：1.8或11 Maven Git Action 获取源码 git clone git://github.com/geoserver/geoserver.git geoserver # or git clone https://github.com/geoserver/geoserver.git geoserver 代码库结构 Each branch has the following structure:
build - release and continuous integration scripts doc - sources for the user and developer guides src - java sources for GeoServer itself data - a variety of GeoServer data directories / configurations 切换到2.22.x分支 # 查看分支 git branch -av # 切换分支 git checkout -b 2.</description>
    </item>
    <item>
      <title>深入研究GeoServer—开篇</title>
      <link>https://fuyi-atlas.github.io/posts/program/geoserver/001/</link>
      <pubDate>Thu, 09 Mar 2023 22:30:19 +0800</pubDate>
      <guid>https://fuyi-atlas.github.io/posts/program/geoserver/001/</guid>
      <description>为什么需要深入研究GeoServer GeoServer是一个开源的、流行的、Java实现的可发布和共享地理信息数据的软件服务器，是WMS、WCS、WFS的标准实现，含WMTS GeoServer功能强大，但是我可能只会用到其中的一两个部分，比如坐标转换与WMTS服务。可以通过研究将其进行提取和重组，形成符合我要求的，更加精简方便的软件服务器 GIS后端开发绕不过去的知识点 如何进行研究 开发环境搭建 通过WMTS请求链接到源码 通过源码进行研究学习 … 未完待续&amp;hellip;</description>
    </item>
    <item>
      <title>微天气-开发环境准备</title>
      <link>https://fuyi-atlas.github.io/posts/program/micro-weather/004/</link>
      <pubDate>Wed, 29 Jun 2022 21:50:34 +0800</pubDate>
      <guid>https://fuyi-atlas.github.io/posts/program/micro-weather/004/</guid>
      <description>前言 本文用于说明本次开发所使用的环境，以及环境的搭建过程。
操作系统 Windows 10 专业版
其实我当时使用的操作系统的Arch Linux，开发完成后才又重装回Windows。
现在又用回了Fedora 38 Workstation @time 2023.10.07
服务端 服务端使用Java语言进行开发，项目构建使用Maven(Gradle)，开发工具使用Idea，服务发布使用Docker，下面是具体的版本：
JDK: OpenJDK 11 Gradle: 7.3.2 Maven: Idea: IntelliJ IDEA 2022.1.3 (Community Edition) Docker: Linx Docker Desktop Version 4.23.0 (120376) [Engine: 24.0.6] 小程序 首先需要自行完成小程序的注册，具体可以参考官方文档。
其次，下载并安装小程序开发工具，参见下载页面。
最后，调试基础库选择：2.24.6
参考 开发者工具中无法显示echart或显示异常
在MobaXterm进入ssh终端后，键入上下左右出现乱码
win10上修改docker的镜像文件存储位置
WSL2 迁移 Docker 镜像存储位置
说明 如有冒犯，我在这里先向您道歉，还请联系我进行处理
email: thread_zhou@126.com</description>
    </item>
    <item>
      <title>微天气-模型设计</title>
      <link>https://fuyi-atlas.github.io/posts/program/micro-weather/003/</link>
      <pubDate>Wed, 01 Jun 2022 22:45:39 +0800</pubDate>
      <guid>https://fuyi-atlas.github.io/posts/program/micro-weather/003/</guid>
      <description>前言 这是一个前后端分离的项目，后端使用Java进行开发，而前端通过微信小程序实现。
功能结构 可从上图得知，部分功能已去除：
消息 消息推送 紧急情况推送 用户 个人中心 模型设计 用户信息（UserInfo） id Long 主键 oid String OpenID uid String UnionID name String 昵称 phone_num String 手机号 avatar String 头像地址 authState String 登录状态 Silence 静默登录（目前程序的访问是需要存在登录态的） Authorized 已授权 createTime Timestamp 记录创建时间 updateTime Timestamp 记录更新时间 行政区划信息（DistrictInfo） 使用全国行政区划信息填充，含空间数据，数据粒度到区县。目前仅支持国内数据。
id Long 主键 name String 行政区名称 grade Integer 行政区级别 1：省级行政区 2：地级行政区 3：县级行政区 4：乡镇级行政区 code String 行政区代码 centerPoint Point 行政区中心点（空间数据） bounds Geometry 行政区边界（空间数据） 关注城市（FollowCity） id Long 主键 userId Long 用户ID districtId Long 行政区划ID districtName String 行政区划名称 districtCode String 行政区划编码 orderNum Integer 序号，自然数，从1开始 createTime Timestamp 记录创建时间 天气信息 由于天气数据均来自第三方，目前数据格式于和风天气对齐。</description>
    </item>
    <item>
      <title>微天气-技术预研</title>
      <link>https://fuyi-atlas.github.io/posts/program/micro-weather/002/</link>
      <pubDate>Wed, 13 Apr 2022 23:19:11 +0800</pubDate>
      <guid>https://fuyi-atlas.github.io/posts/program/micro-weather/002/</guid>
      <description>前言 俗话说：磨刀不误砍柴工。
我想做一个天气类别的小程序，以此进行全栈开发能力的试炼。我想这会是一个微信小程序、是一个可以正常使用的小程序，以Java进行服务端开发，以Mapbox实现天气数据可视化。
但是我是一个后端开发工程师，我不怎么会写页面，我特别的讨厌写CSS。我也没有接触过微信小程序开发，也仅仅知道过Mapbox可以实现好看的地图。所以我需要进行一定的预研，避免后期花费更大的精力用来调整本可以避免的问题。
下面是我计划实现的功能列表：
利用网络接口获取数据（昨日天气、当前天气、预报天气） 实现实时天气与预报数据查看 紧急情况推送 利用地图（mapbox）进行数据可视化 天气分享（图片分享，页面分享） 常用地址 消息推送 个人信息 登录授权 应用Promise进行异步网络请求 使用阿里巴巴矢量图标库作为图标数据源 echarts图标展示 接入疫情数据？ 预研对象 天气数据 天气数据需要是真实的、可用的。那么可以通过网络中提供的天气API进行获取。
通过一定的检索后，我选定了两个天气平台，分别是：和风天气、心知天气。
高德天气：大平台，但是目前服务类目比较少
彩云天气：免费接口几乎没有，收费又太贵
心知天气 心知天气试用版与开发者版开发产品几乎等同，且开发者版收费也不贵。最为关键的是，支持以经纬度方式进行天气查询。
和风天气 几乎可以免费使用其提供的所有 API，且同样支持经纬度方式进行天气查询。
小结 对比了这两者，发现至少都需要注册为开发者之后，才可以较好的使用其服务。且两者的开发者认证均需要实名。
关于天气API的选择，我最终选择了和风天气，倒不是因为它可以免费使用。其实，刚开始的时候我更倾向于使用心知天气，因为它还可以直接查昨天的天气（和风对于历史天气的查询比较麻烦）。但是和风天气首页结合了地图进行可视化，而且还提供有APP可以使用（方便参考）。再加上，我想了想，其实我并没有迫切的需要知道昨天的天气情况。
其实最重要的原因在于：我先注册了心知天气（需要审核），过了半天后再去注册了和风天气（需要审核），但是最先通过审核的是和风天气（耗时大概也就半天左右，我是在春节期间注册的）。
前端技术 我并没有想要精通前端技术，但是我需要比较体系的了解一下前端技术，方便进行小程序开发。所以我在B站找了两门前端视频学习（粗略的刷了一遍）：
【尚硅谷】Web前端零基础入门HTML5+CSS3基础教程丨初学者从入门到精通 千锋web前端开发项目教程_1000集完全零基础入门HTML5+CSS3+JS到精通 微信小程序 官方文档足以
Mapbox 这里存在一个遗憾，小程序原生并不支持使用如mapbox这样的第三方地图框架，初始想法是通过webview的方式使用mapbox，但是遗憾的是，webview并不对个人类型的小程序开放使用。
所以，退而求其次，选择腾讯地图（及其提供的样式）实现地图浏览。
UI UI部分参考和风天气APP，以及WEUI
总结 天气API使用和风天气（若有空余可考虑抽取一套统一的API，可组合或切换数据来源） 地图使用腾讯地图（微信小程序解决方案，主要在于个性化样式的使用） 基于自定义服务端实现天气代理以及小程序静默登录 UI参考和风天气APP实现 参考 最好的6个免费天气 API 接口对比测评 心知天气-价格方案 和风天气-FAQ H5+Javascript技术结构图 腾讯位置服务-微信小程序解决方案-个性化地图样式 说明 如有冒犯，我在这里先向您道歉，还请联系我进行处理
email: thread_zhou@126.com</description>
    </item>
    <item>
      <title>微天气-序章</title>
      <link>https://fuyi-atlas.github.io/posts/program/micro-weather/001/</link>
      <pubDate>Sun, 10 Apr 2022 22:10:30 +0800</pubDate>
      <guid>https://fuyi-atlas.github.io/posts/program/micro-weather/001/</guid>
      <description>前言 天气小程序产生于2022年年初，目的是用于验证自己是否有进入全栈开发（仅前后端）的能力。该项目从2022年1月12号正式启动，于2022年3月19日发布一阶段最终版本（1.1.9），总体耗时2个月零7天。从内容完整度以及界面友好程度来说，我给自己70分。
完成内容 和风天气API接入，可实现实时天气、实时空气、24小时天气预报、7天天气预报 使用echarts for wechat进行24小时天气预报展示 通过腾讯位置服务提供的微信小程序解决方案实现地图个性化展示（目前使用风格：白浅） 通过自建服务实现小程序静默登录 通过自建服务实现关注城市的持久化管理 实现天气分享功能，通过生成一张图片进行分享，可直接分享给朋友或群组 默认通过定位获取所在位置的天气数据 天气数据均通过服务端代理进行获取，从而避免相关key直接暴露在客户端 提供通过经纬度查询所处行政区划的服务，提供行政区划查询服务，皆可获取对应行政区划中心点基于边界数据，数据坐标为4326 服务通过github action自动化进行docker构建，并推送到阿里云镜像服务仓库，而后在阿里云ecs中直接拉取docker进行部署 图片服务则是通过nginx实现反向代理，图片由docker容器内服务创建，通过docker文件映射功能映射到云主机，再通过nginx可实现图片的访问 服务与图片均实现域名访问，且均提供ssl证书 不足 未实现天气地图可视化，即基于mapbox进行地图可视化（webview需要企业认证资质） 未提供坐标转换功能，因目前使用的是腾讯地图（gcj02，即从地图获取的数据均为gcj02），行政区划数据为4326（wgs84），目前是直接将4326作为gcj02进行使用（因为数据的粒度为区县，所以差异不会很大，除非在行政区边界处可能会出现行政区显示错误问题） 未完整实现小程序朋友圈分享功能，因该功能需要所分享页面的数据可直接获取，且分享页面小程序登录功能已被限制，所以目前无法直接提供数据获取服务（需要进行登录态校验，考虑到被攻击的可能） 未完成天气预警数据接入与提示功能 未完成数据推送、个人主页、图层管理功能 分享图片中未实现天气云图叠加功能，仅获取了所在位置范围的影像图与相关注记 服务端代码封装度不够，且DDD的认知不足，导致实践乱七八糟 内容 我计划将拂衣天气开发的完整过程通过文章的方式记录下来，下面是我对该整体内容的编写计划：
Name Key Words Summary 序章 前期调研 模型设计 开发环境准备 行政区划数据准备 小程序静默登陆实现 小程序开发（一） 说明主页布局构建，组件拆分情况，实现地图加载以及定位 小程序开发（二） 实现上下滑动功能开发，以及左右滑动组件封装 小程序开发（三） 实时天气栏卡片、文字描述、底部7天天气预报以及Footer部分开发 小程序开发（四） 完成echarts组件封装 天气代理服务开发 提供实时天气、实时空气质量、24小时天气预报、7天天气预报代理服务开发 小程序开发（五） 完成天气部分API对接 行政区划服务开发 提供行政区划查询服务 关注城市服务开发 提供对城市的关注与取消关注能力 小程序开发（六） 完成天气图片分享功能 小程序开发（七） 完成城市选择页面开发与数据API对接 Github Action服务发布 小程序服务发布 终篇 参考 注：拂衣天气小程序的界面设计与交互设计主要参考和风天气APP。当前所述拂衣天气小程序的开发主要用于学习。
致敬和风天气！
和风天气 和风天气开发平台 </description>
    </item>
    <item>
      <title>深入拆解Java虚拟机（一）</title>
      <link>https://fuyi-atlas.github.io/posts/program/java/jvm/002/</link>
      <pubDate>Tue, 24 Nov 2020 22:06:42 +0800</pubDate>
      <guid>https://fuyi-atlas.github.io/posts/program/java/jvm/002/</guid>
      <description>1. 为什么 Java 需要运行时环境 1.1. Java 程序的启动方式 IDE中启动，比如：Eclipse、IntelliJ IDEA 构建为 jar，通过命令行的方式启动，比如：java -jar application.jar 使用构建工具（如：Gradle、Maven）启动，比如 SpringBoot 应用启动：gradle bootRun、mvn spring-boot:run 1.2. JRE 是什么 在这里引用极客时间课程Java核心技术面试精讲中的一段话
我们日常会接触到 JRE（Java Runtime Environment） 或者 JDK（Java Development Kit）。JRE，也就是 Java 运行时环境，仅包含运行 Java 程序的必须组件，包括 Java 虚拟机以及 Java 核心类库等。而 JDK 可以看作是 JRE 的一个超集，提供了更多工具，比如编译器、各种诊断工具等。
1.3. 为什么需要运行时环境 不是有这么一句话么，计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决。话说回来，Java 代码运行之所以需要运行时环境，主要是由于以下几个方面的原因：
Java 语言语法非常复杂，抽象程度高，直接在硬件上运行这种复杂的程序并不现实（并不是不可以，但是这样造成与相应硬件的强耦合，且不便于抽象和复杂语法的实现。），所以需要在运行之前进行一番转换。
实现平台无关性、做到 “Write once, run anywhere”，获得跨平台的能力。这样便需要一个中间层进行解耦，达到上层统一编码、下层跨越平台、中间实现兼容（所以，Java 语言的跨平台特性是由 Java 运行时环境实现的。也就是在不同平台皆有与之相对应的 Java 运行时环境，实现相同定义、不同实现。这样的思想是不是很熟悉，当然，这仅是我的理解）。
提供托管环境（Managed Runtime），该托管环境可以代替我们处理一些通用的、容易出错的、高难度的行为，比如自动内存管理、垃圾回收、安全权限动态检测等。
2. Java 代码在虚拟机中是怎样运行的 2.1. 虚拟机视角 执行 Java 代码首先需要将它编译而成的 class 文件加载到 Java 虚拟机中，加载后的 Java 类会被存放到方法区中。实际运行时，虚拟机会执行方法区内的代码（需要将字节码翻译为机器码，在 HotSpot 实现中，有解释执行和即时编译两种）。</description>
    </item>
    <item>
      <title>持续交付之标准现行</title>
      <link>https://fuyi-atlas.github.io/posts/program/continuous-delivery/002/</link>
      <pubDate>Tue, 17 Nov 2020 21:54:38 +0800</pubDate>
      <guid>https://fuyi-atlas.github.io/posts/program/continuous-delivery/002/</guid>
      <description>前言 标准先行并不是一个新鲜玩意，不过是先制定事实标准，而后使用这些标准约束之后的行为。俗话说得好：“没有规矩，不成方圆”。在这里，我想说一下我认为的标准先行以及与持续交付的结合，希望不会对你产生误导。
为什么需要标准先行 我们可以先不去问为什么，而是反过来看这个问题。假设在我们的产物交付过程中，没有任何的标准，给你自由，会发生些什么问题。在一阵头脑风暴（抽搐）之后，我做出如下假设：
乱象百出，群魔乱舞。不论是正确的还是错误的产出，解释如此。比如，整体代码的可读性和可维护性直线下降；分支来回穿插，Commit 信息奇奇怪怪；开发、测试环境存在混用，测试数据过于随意；部署由心，同一个应用在不用的主机上存放位置可能还不同等等。
过程、阶段性产物不统一，且质量高低不齐，严重影响系统集成与交付。
高效完成，但前提是有着意见一致、理念相同、水平相当的一群人。
在我的假想中，自由带来的有好也有坏。但是我仍认为大部分的时候出现的都是坏的影响，毕竟要寻找到一群志同道合的人一起共事，就已经是一件很不容易的事了，且不说每个人都是单独的个体，其思想与灵魂亦是独一无二的。所以，不管在什么样的情况下，我们都需要制定标准来约束我们的行为。统一标准下的行为造成的影响几乎是一致的，那么即使是排错、修改时也是有迹可循。（在这里不会抬杠标准与自由的取舍，存在即是合理。但是从两者在大部分时候所能产生的影响来看，我会采取强标准，若自由的方式，但这绝非将两者置为对立关系。）
都有哪些标准先行 没有绝对通用的标准，任何的标准都是不同场景下最佳实践的总结，且需要持续的进行优化，是可以传承的宝贵知识集合。之所以扯这么一段话，我只是想说目前还处于实践阶段，但是这并不影响制定相关的标准。使用过 SpringBoot 开发的大佬都知道什么是约定优于配置，我认为标准亦是如此，即标准之上是约定。在这里，我将需要先行的标准分为了如下几个方面：
开发模式与分支策略（含 Commit 规范） 编码规范（Java、JavaScript） API 设计规范 数据库设计规范 环境隔离 部署规范 发布流水线标准 标准先行与持续交付 总结 参考文献 持续交付36讲 说明 我不是在卖课 本文大部分内容来源于极客时间以及网络博文节选，如有冒犯，我先向您道歉，另还请告知我进行处理，谢谢 邮箱：thread_zhou@126.com </description>
    </item>
    <item>
      <title>jvm 基础入门</title>
      <link>https://fuyi-atlas.github.io/posts/program/java/jvm/001/</link>
      <pubDate>Tue, 10 Nov 2020 22:15:44 +0800</pubDate>
      <guid>https://fuyi-atlas.github.io/posts/program/java/jvm/001/</guid>
      <description>前言 老生长谈，Java是一个什么事物，都有些什么样的特性呢？
Java：Java 是一种广泛使用的计算机编程语言，拥有跨平台、面向对象、泛型编程的特性，广泛应用于企业级Web应用开发和移动应用开发。
Java 编程语言的风格十分接近C++语言。继承了C++语言面向对象技术的核心，舍弃了容易引起错误的指针，以引用取代；移除了C++中的运算符重载和多重继承特性，用接口取代；增加垃圾回收器功能。在Java SE 1.5版本中引入了泛型编程、类型安全的枚举、不定长参数和自动装/拆箱特性。Sun微系统对 Java语言 的解释是：“Java 编程语言是个简单、面向对象、分布式、解释性、健壮、安全与系统无关、可移植、高性能、多线程和动态的语言”。
Java 不同于一般的编译语言或解释型语言。它首先将源代码编译成字节码，再依赖各种不同平台上的虚拟机来解释执行字节码，从而具有“一次编写，到处运行”的跨平台特性。在早期 JVM 中，这在一定程度上降低了 Java 程序的运行效率。但在J2SE1.4.2发布后，Java 的运行速度有了大幅提升。
以上内容来自于维基百科，给定了 Java 一个明确的定义，但是对于Java平台以及特性并没有很好的归结，下面是我截取自极客时间Java核心技术面试精讲的部分内容：
Java 本身是一种面向对象的语言，最显著的特性有两个方面，一是所谓的“书写一次，到处运行”（Write once, run anywhere），能够非常容易地获得跨平台能力；另外就是垃圾收集（GC, Garbage Collection），Java 通过垃圾收集器（Garbage Collector）回收分配内存，大部分情况下，程序员不需要自己操心内存的分配和回收。
我们日常会接触到 JRE（Java Runtime Environment）或者 JDK（Java Development Kit）。 JRE，也就是 Java 运行环境，包含了 JVM 和 Java 类库，以及一些模块等。而 JDK 可以看作是 JRE 的一个超集，提供了更多工具，比如编译器、各种诊断工具等。
对于“Java 是解释执行”这句话，这个说法不太准确。我们开发的 Java 的源代码，首先通过 Javac 编译成为字节码（bytecode），然后，在运行时，通过 Java 虚拟机（JVM）内嵌的解释器将字节码转换成为最终的机器码。但是常见的 JVM，比如我们大多数情况使用的 Oracle JDK 提供的 Hotspot JVM，都提供了 JIT（Just-In-Time）编译器，也就是通常所说的动态编译器，JIT 能够在运行时将热点代码编译成机器码，这种情况下部分热点代码就属于编译执行，而不是解释执行了。
在维基百科给出的定义中，提到 Java 编程语言是解释性的语言，而在Java核心技术面试精讲中提出该说法不太准确，我比较认可后者的看法。类似 JIT、AOT（Ahead-of-Time Compilation，在执行前直接将字节码编译成机器代码，静态编译） 技术的出现以及实践，使得 Java 的解释性变得不那么纯粹，此时从不同的角度可能会得到不同的结果，比如从占比上考虑，那么 Java 还是解释性的；如果从 JIT 的角度看，此刻的 Java 是编译性的；而从总体的角度来看，则是混合性的（解释和编译的混合）。</description>
    </item>
    <item>
      <title>持续交付（一）—— 持续交付是什么，和DevOps有什么关系</title>
      <link>https://fuyi-atlas.github.io/posts/program/continuous-delivery/001/</link>
      <pubDate>Mon, 09 Nov 2020 21:53:09 +0800</pubDate>
      <guid>https://fuyi-atlas.github.io/posts/program/continuous-delivery/001/</guid>
      <description>前言 在我们日常的划水中，常常听到持续集成、持续部署、持续交付、DevOps，那么这些名词到底是什么意思？对我们的日常工作有什么作用呢？能够提高划水的效率呢？其实对于名词的解释始终还是千人千面，不同环境下必然存在不同的产物，我今天想说一说我自己的理解，希望不会对你有误导。
什么是持续交付 持续交付：（英语：Continuous delivery，缩写为 CD），是一种软件工程手法，让软件产品的产出过程在一个短周期内完成，以保证软件可以稳定、持续的保持在随时可以释出的状况。它的目标在于让软件的建置、测试与释出变得更快以及更频繁。这种方式可以减少软件开发的成本与时间，减少风险。
由上可知，持续交付的关注点在于以下几个方面：
短周期 随时可释出 频繁构建 持续交付也可以拆开分析，所谓持续便是一直的频繁的做某件事，有一种开始也是结束，结束也是新的开始的感觉，需要闭环反馈来支持下一个阶段的持续行为；而交付则表示针对当前交付目标释出可行的产物。上面提到的随时可释出和频繁构建很好的体现了持续交付的行为特性，而短周期则是表示每一个阶段的交付过程应该在一个短的周期之内完成，因为短周期意味着快速交付、快速反馈、快速反应并快速的循环反复，而长周期必然会加大一次交付流程的耗时（加大试错成本，无法快速反应），所以这样才能够达到持续交付的目的（随时可交付）。至于什么才是合适的短周期，这个需要结合企业或团队的具体情况（比如项目当前所处阶段、研发人员素质、研发上线流程等）进行考虑。
说了这么多，那么持续交付是以什么样的形式。如何落地到我们日常的工作中的呢？结合美团外卖持续交付分享（美团外卖持续交付的前世今生）和极客时间课程持续交付36讲，我总结了如下的一种描述。（希望不会将你带偏）
关于持续交付，不同的企业、不同的团队站在不同的角度会存在不同的定义，我们可以把持续交付定义为一个产品价值的开发框架（站在企业的角度）、一套软件工程方法论以及许许多多最佳实践的集合。持续交付的落地便是开发框架或软件工程方法论与实际情况的结合的实践（也可以说是最佳实践的排列组合），更详细的实践情况还请接着往后看。
持续集成、持续部署、DevOps和持续交付的关系 持续集成 持续集成：（英语：Continuous integration，缩写CI），是一种软件工程流程，是将所有软件工程师的软件工作副本持续集成到共享主线（mainline）的一种举措。该名称最早由葛来迪.布区（Grady Booch）在他的布区方法中提出，在测试开发驱动（TDD）的实践中，通常还会搭配自动单元测试。持续集成的提出主要是为了解决软件进行系统集成时面临的各种问题，极限编程称这些问题为集成地狱（integration hell）。
持续集成的关注点在于：
频繁集成 有效协作 自动化测试 我们通常会将软件研发工作拆解，拆分成不同模块或不同团队进行编码，编码完成后，进行集成构建和测试。这个从编码到构建再到测试的反复持续过程，就叫做持续集成。由持续集成的定义可联想到版本控制，如 Git，进而可以关联到分支策略（如：Git Flow、GitHub FLow、GitLab Flow），可以说分支策略是持续集成的前置条件。一般情况下，会有一个分支作为集成使用，加上多个特性分支（这里和具体的分支策略强相关，并不是所有团队的都是一样的），当特性分支开发完毕，通过 PR 请求合并到集成分支，此时会触发持续集成工作流程，保证待合并的分支内容是有效的，只有通过持续集成流程验证，才能合并到集成分支。
持续部署 持续部署：（英语：Continuous deployment，缩写为CD），是一种软件工程方法，意指在软件开发流程中，以自动化、频繁而且持续性的，将软件部署到生产环境（production environment）中，使软件产品能够快速的发展。持续部署可以被整合到持续集成与持续交付的流程之中。
持续部署的关注点在于：
自动化的 频繁的 持续性 生产环境 在一些企业的软件部署工作中，仍然存在全人工操作的方式。如果只是单纯的安装部署目的还较为容易（不过繁琐的配置，人工的不规范、不确定性，部署的耗时等都是成本）；而如果是已上线的服务的部署工作（服务更新），此时的涉及面以及受影响的范围就比较大了。就算释出的产物已经可以达到可交付的标准，但是要使得用户真正可用，还需要跨越安全、快速以及稳定部署的障碍。那么是否可以将部署的场景和过程进行抽象，使用统一的、规范的、自动化的方法论和流程来约束和实现部署的过程。而持续部署便是这样的一套方法论及实践工具集，旨在规范部署行为，通过自动化提高部署效率，达到持续部署目的。
持续集成、持续部署与持续交付的关系 当提到持续交付的时候，总能关联到持续集成与持续部署，我也一直傻傻分不清这三者之间有什么区别，是什么样的关系。不过从前面给出的定义和关注点可以知道，持续集成侧重于编码阶段内多人协作产物集成的有效性，持续部署侧重于将产物部署到生产环境，而持续交付则侧重于需要随时可释出；而相同点在于他们三者都推崇持续性，即存在一个反馈的过程，且反馈的结果作为下一阶段持续的支持。
再说到持续集成、持续部署和持续交付之间的关系，这里还有一个比较有趣的地方，那就是在不同的视角下，三者的关系并不一样，这里借鉴美团外卖分享的内容（美团外卖持续交付的前世今生）举例，从研发和产品的角度来分析这三者的关系。
研发视角：我们可以看到大部分研发团队，会从软件研发的角度进行定义，他们将软件的开发步骤拆解为持续集成、持续交付、持续部署，其中持续集成指开发人员从编码到构建的过程；持续交付则作为持续集成的自然延续，指将已经集成构建完成的代码，交给测试团队进行测试的过程；持续部署指将测试通过的软件交付给用户的过程。在研发的视角下，持续交付就是一个承上启下的过程，与持续集成形成了闭环，而又为将来达到持续部署做下了准备。此时持续集成 + 持续交付 + 持续部署便是一条完整的发布流水线。
产品视角：产品团队会站在产品的角度来看，他们认为持续交付，是从需求的 PRD 文档提出来，到用户能够感受这个需求的周期。也就是说，此时持续交付是完整的包含了持续集成与持续部署，但是持续交付涵盖范围是大于持续集成 + 持续部署。并且，此时的持续交付流程本身就包含了一条完整的发布流水线。
借用持续交付36讲中的 发布流水线 示意图
说到这里已经不难看出，影响三者之间相互关系的因素主要在于对于持续交付的定位。在这里先说说我自己的看法，我认为持续交付的核心要义在于：短周期、时刻可释出、持续构建，即在于持续的产出与持续验证，由产出与验证形成闭环，进而相互推动，以达到快速反应，快速实现，持续优化。而短周期便是一次交付过程耗时的预定义，也是对于效率的要求，但一定不是对用人的压榨（去你xxx）。在持续交付中，交付对象不一定就是最终用户，所以千万不要认为一定要做到端到端完整才是持续交付。持续交付是一个周期性、可持续的行为，可以只是研发到测试的闭环，此时于研发而言交付对象是测试团队，交付物为通过持续集成验证的代码；也可以如产品视角一般，从需求的 PRD 提出来到用户能够感受到这个需求的周期，此时交付对象为用户，交付物为可用的产品。
所以持续交付可以只是一套方法论，可以是产品价值开发框架，也可以是一部分流程实践。于我个人而言，我更认同持续交付是一套方法论（兼产品价值开发框架），由此指导持续交付体系的建设。如果你问我持续交付体系实践中使用到的技术是不是持续交付，我会说，在其中使用到的技术或工具只是当前持续交付体系建设的一个组成部分。所以，关于持续集成、持续部署、持续交付三者之间的关系，我认同为：三者相互渗透（可能这个词不是很恰当），并没有绝对的独立。
DevOps DevOps：（是 Development 和 Operations 的组合词），是一种重视“软件开发人员（Dev）”和“IT 运维技术人员（Ops）”之间沟通合作的文化、运动或惯例。通过自动化“软件交付”和“架构变更”的流程，来使得构建、测试、发布软件能够更加地快捷、频繁和可靠。
传统的软件组织将开发、IT 运维和质量保障设为各自分离的部门，再这样的环境下如何采用的新的开发方法（例如敏捷软件开发），是一个重要的课题。按照从前的工作方式，开发和部署，不需要 IT 或者 QA 支持（跨部门的持之），而现在却需要极其紧密的多部门协作。而 DevOps 考虑的不仅仅是软件部署，它是一套针对这几个部门间沟通与协作问题的流程和方法。</description>
    </item>
    <item>
      <title>合并区间</title>
      <link>https://fuyi-atlas.github.io/posts/program/algorithm/merge-interval-001/</link>
      <pubDate>Wed, 16 Sep 2020 21:41:52 +0800</pubDate>
      <guid>https://fuyi-atlas.github.io/posts/program/algorithm/merge-interval-001/</guid>
      <description>前言 在工作中，还没有仔细的去研究过一些算法实现，直到最近面试才知道，自己的数据结构与算法的功底这么差。 知道总是比不知道的强，那么就一个一个的来吧，我也会通过文字的方式记录自己的算法道路，下一个目标就是LeetCode。
如题（某次面试题） 给定⼀个按开始时间从⼩到大排序的时间区间集合，请将重叠的区间合并。时间区间集合⽤用一个二维数组表示， 二维数组的每⼀行表示⼀个时间区间（闭区间），其中 0 位置元素表示时间区间开始，1 位置元素表示时间区间结束。 例 1：输入：[ [1, 3], [2, 6], [8, 10], [15, 18] ]返回： [ [1, 6], [8, 10], [15, 18]] 解释：时间区间 [1, 3] 和 [2, 6] 有部分重叠，合并之后为 [1, 6] 例 2：输入：[[1, 4], [4, 5]]返回：[[1, 5]]解释：时间区间[1，4] 和 [4，5]重叠了了⼀一个时间点，合并之后为 [1，5] 需要实现的⽅法原型：int[][] merge(int[][] intervals)
二维数组中的每一行表示一个时间区间（闭区间），其中0位置表示开始时间，1位置表示结束时间 给定的时间区间集合按照开始时间从小到大排序，即为有序 这里给出的题还是比较简单的，因为给定的时间区间集合已经是一个有序的集合了，需要实现的内容只剩下区间合并了。 由题中可知，需要合并具有重叠部分的区间，只要确定了重叠的条件，便基本完成了解答。
在已完成时间区间开始时间从小到大的排序后，那么此时的时间区间集合在时间横轴上回呈现类似上图的情况， 此时可以从小到大遍历时间区间集合，进行合并或收集。这里需要一个容器存放目标结果，也就是没有任何交集的时间区间。 具体实现代码如下所示：
/** * 时间区间合并方法 * * @param intervals * @return */ public static int [][] merge(int [][] intervals) { // 二维数组行数 int rows = intervals.</description>
    </item>
    <item>
      <title>Socket简单案例实现</title>
      <link>https://fuyi-atlas.github.io/posts/program/network-program/simple-case-001/</link>
      <pubDate>Mon, 03 Aug 2020 22:17:53 +0800</pubDate>
      <guid>https://fuyi-atlas.github.io/posts/program/network-program/simple-case-001/</guid>
      <description>前言 终于还是吃了自己的狗粮&amp;hellip;&amp;hellip;
关于 客户端-服务端 网络模型 常规情况下，网络应用都会存在客户端和服务器端，比如平时外卖应用一样，我们在外卖应用上的操作，都对应着客户端应用向服务器发起请求，并收到响应的过程。服务器为客户端提供业务数据支持，客户端则为用户提供交互界面。
在网络编程中，具体到客户端 - 服务器模型时，我们经常会考虑是使用TCP还是UDP，其实它们二者的区别也很简单：在TCP中连接是谁发起的，在UDP中报文是谁发送的。在TCP中，建立连接是一个非常重要的环节。区别出客户端和服务器，本质上是因为二者编程模型是的不同的。
服务器端需要在一开始就监听在一个确定的端口上，等待客户端发送请求，一旦有客户端建立连接，服务器端则会消耗一定的计算机资源为它服务。
客户端相对简单，它向服务器的监听端口发起请求，连接建立之后，通过连接通路和服务器端进行通信。
还有一点要强调的是，无论是客户端还是服务器端，它们运行的基本单位都是进程（Process），而不是机器。一个客户端，可以同时建立多个到不同服务器的连接；而服务器更是可能在一台机器上部署运行多个服务。
什么是 socket socket是一种操作系统提供的进程间通信机制。这里并不局限于本地，可以是本地进程间的通信，也可以是远端进程间的通信。在操作系统中，通常会为应用程序提供一组应用程序接口（API），称为套接字接口（socket API）。应用程序可以通过套接字接口来使用套接字（socket），已进行数据交换。
这里要注意一下，我们常说的TCP和UDP只是传输层协议，是一种约定。TCP三次握手则是基于TCP协议创建网络通路，该通路的具体创建与实现还是socket完成。socket是我们用来建立连接、传输数据的唯一途径。
如何使用 socket 建立连接 通过前面的客户端 - 服务器模型，我们知道至少需要一对套接字才能进行网络连接的建立，它们分别是服务端套接字和客户端套接字，这里我们先从服务端说起。
服务端准备连接过程 创建套接字（我们这里会使用 TCP的实现） 绑定监听地址：即为绑定需要监听的 IP地址以及 端口号，这里也可以使用本机 IP，但是考虑到部署环境 IP可能会发生变化，所以这里需要进行 IP地址的绑定（比如进行通配地址指定，或者主机存在多张网卡时指定具体的 IP）。如果不显式的指定端口号，就意味着把端口的选择权交给操作系统内核来处理，操作系统内核会根据一定的算法选择一个空闲的端口，完成套接字的绑定。 开启套接字监听模式：bind函数只是实现套接字与地址的关联，如同登记了电话号码，如果要让别人打通带年华，还需要我们把电话设备接入电话线，让服务器真正处于可接听的状态，这个过程需要依赖 listen函数。这里可以这么理解，socket存在 主动和 被动模式，比如服务器就是处于 被动模式下，它需要等待客户端套接字的 主动连接。而 listen函数便是可以将套接字设置为 被动模式，即告诉内核：“我这个套接字是用来等待用户请求的”。 建立连接（accept阻塞）：在客户端连接请求到达时，服务端应答成功，便完成连接建立。 package com.zhoujian.socket; import java.util.concurrent.ExecutorService; import java.util.concurrent.Executors; /** * 线程池工具类 * @author zhoujian */ public class ExecutorServicePool { /** * 初始化线程池 */ public static ExecutorService executorService = Executors.newFixedThreadPool(10); } package com.</description>
    </item>
    <item>
      <title>PostgreSQL11.2 数据恢复记录（From Physical Files）</title>
      <link>https://fuyi-atlas.github.io/posts/program/database/postgresql/11.2-data-recovery/</link>
      <pubDate>Thu, 16 Jul 2020 22:03:58 +0800</pubDate>
      <guid>https://fuyi-atlas.github.io/posts/program/database/postgresql/11.2-data-recovery/</guid>
      <description>前言 记录一下PostgreSQL11.2的数据恢复，场景是这样的，我们在A主机（windows server 2008）上安装一个PostgreSQL11.2，突然有一天A主机坏掉了，只能将磁盘卸载下来挂载到新的主机上，但是如何才能快速有效的将之前磁盘中的数据恢复呢？
重新注册为windows服务（失败） 这里我使用主机B（windows server 2012 R2）进行重新注册 参考重新注册PostgreSQL服务
找到并PostgreSQL的安装路径，在此启动命令行工具 使用pg_ctl命令将PostgreSQL11.2重新注册为服务，该命令的具体用法和写法可以查看pg_ctl帮助文档（pg_ctl &amp;ndash;help） 结果很现实，没有能够成功，具体的原因未知，返回提示消息为：无法注册服务，错误码1783
此路不通，那我只能换一种方式。
替换PostgreSQL的数据目录（成功） PostgreSQL的数据是存储到data目录下，具体的目录是服务安装的时候指定的，默认是在服务的安装目录下。只要你还拥有完整的data目录，那么你是完全可以从这一份原始物理文件进行数据恢复的。
在这里我使用主机C（windows10）作为测试机 先在C主机上安装PostgreSQL11.2 将原始data目录拷贝到C主机PostgreSQL数据存在目录（即data）的同级目录，并重命名为data-bak（命名随意，符合规则且不冲突就行） 然后参照Change the default PGDATA directory on Windows完成剩余替换步骤 停止C主机的PostgreSQl11.2服务 修改注册表，用意为重新指定服务使用的data目录，替换为我拷贝的data-bak目录，注册表路径：HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\pgsql-some version，修改ImagePath项的value值中 -D 参数 到windows服务管理中查看PostgreSQL服务属性，检验可执行文件路径中是否已经指向了data-bak路径 重启PostgreSQL服务 这里有坑，请注意！ 如果出现服务启动后停止，请进行以下检查： 1. 检查 data-bak 目录权限，确保该目录和同级的 data 目录的权限一致 2. 检查 是否存在 postmaster.pid 文件，如果存在将其删除（这个未测试，听说可以哦） 3. 检查 postgresql.conf 文件，保持端口号、语言环境（lc_messages、lc_monetary、lc_numeric、lc_time）等基础配置和当前的服务一致，避免配置异常导致启动失败 4. 检查 pg_hba.conf 文件 我按照步骤完成了以上操作，但是发现还是无法在服务管理中启动服务，我通过事件查看器查看日志，也只是看到超时导致启动失败，遂又google+baidu一把，获取链接一个postgresql 在等待服务器启动时超时
在这里提到需要执行一个命令：pg_resetwal -f E:\Server\PostgreSQL\11\data-bak 执行成功会得到打印信息：Write-ahead log reset
然后可以直接在命令行验证是否可以正常启动：pg_ctl -D E:\Server\PostgreSQL\11\data-bak
登录密码应该是旧的密码，我这里是直接使用刚安装PostgreSQL产生的postgresql.conf 替换了data-bak中的postgresql.conf ，所以我的登录密码是新设置的，你实在不知道你就改嘛
我到这里已经能够成功启动了，但是还有坑，还是因为语言环境导致的，如果你的语言环境都一致，那么应该没啥问题了，问题解决方案看后记，最下面</description>
    </item>
    <item>
      <title>Spring Data JPA 使用入门</title>
      <link>https://fuyi-atlas.github.io/posts/program/spring-data-jpa/quick-start/</link>
      <pubDate>Tue, 14 Jul 2020 22:12:23 +0800</pubDate>
      <guid>https://fuyi-atlas.github.io/posts/program/spring-data-jpa/quick-start/</guid>
      <description>前言 我一直认为 Spring Data JPA 是一个好东西，有着自己独特的黑魔法。但是由于目前接触甚少，不知道该如何开启。所以想通过从无到有的过程，逐渐的去认识它，搞清楚它与Mybatis的关系，如果站在架构的角度看会怎么怎么样的情况。在这个过程中，会使用文字的方式将过程记录下来，也算是一点经历。
Spring Data JPA 介绍 From spring.io：Spring Data JPA是Spring Data系列的一个组成部分，可以轻松快捷的实现数据访问层的增强支持，这使得基于Spring且使用了数据库访问技术的应用程序更加容易构建。Spring Data JPA 内置了简单数据库读写操作，包括分页查询，并提供接口以待增强。
Spring Data JPA 是基于Hibernate（在3.2版本中便对JPA提供了完全的支持）、JPA规范的基础上封装的一套ORM框架，可以说就是JPA规范的一个实践落地的产品。Spring Data JPA的内置实现中提供了包括增删改查、分页、自定义SQL的常用功能，且提供接口以待拓展增强。基于Spring Data JPA可以简洁的代码，快速的实现对数据库的访问。
使用示例 环境说明:
windows 10 专业版 IntelliJ IDEA 2019.3.1 JDK 1.8 maven 3.6.1 Spring Boot 2.2.5.RELEASE 引入依赖 &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.springframework.boot&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;spring-boot-starter-data-jpa&amp;lt;/artifactId&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;!-- 我这里使用mysql作为数据存储 --&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;mysql&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;mysql-connector-java&amp;lt;/artifactId&amp;gt; &amp;lt;scope&amp;gt;runtime&amp;lt;/scope&amp;gt; &amp;lt;/dependency&amp;gt; &amp;lt;dependency&amp;gt; &amp;lt;groupId&amp;gt;org.projectlombok&amp;lt;/groupId&amp;gt; &amp;lt;artifactId&amp;gt;lombok&amp;lt;/artifactId&amp;gt; &amp;lt;optional&amp;gt;true&amp;lt;/optional&amp;gt; &amp;lt;/dependency&amp;gt; 定义一个简单实体 import javax.persistence.Entity; import javax.persistence.GeneratedValue; import javax.persistence.GenerationType; import javax.persistence.Id; /** * @author zhoujian */ @Entity public class Customer { @Id @GeneratedValue(strategy= GenerationType.</description>
    </item>
    <item>
      <title>Spring Data JPA 与 Mybatis 对比分析</title>
      <link>https://fuyi-atlas.github.io/posts/program/spring-data-jpa/spring-data-jpa-vs-mybatis/</link>
      <pubDate>Tue, 14 Jul 2020 21:49:59 +0800</pubDate>
      <guid>https://fuyi-atlas.github.io/posts/program/spring-data-jpa/spring-data-jpa-vs-mybatis/</guid>
      <description>前言 其实，手写jdbc也是蛮好玩的&amp;hellip;
在企业开发过程中，除去一些特殊的要求外，基本上都会使用全自动或半自动的ORM框架代替原生JDBC进行数据库的访问。而在具体项目设计时，常常会根据项目业务情况进行技术选型。其中常用的ORM框架有：
Mybatis Hibernate Spring Data JPA JdbcTemplate 在这里我们主要讨论Mybatis与Spring Data JPA。
Spring Data JPA 1、JPA是什么 维基百科：JPA（Java Persistence API，Java持久化API）是一个Java应用程序接口规范，描述了使用Java标准平台（Java SE）和Java企业版平台（Java EE）的应用中的关系数据的管理。
Spring Data JPA 全面解析：JPA (Java Persistence API) 是 Sun 官方提出的 Java 持久化规范。它为 Java 开发人员提供了一种对象/关联映射工具来管理 Java 应用中的关系数据。他的出现主要是为了简化现有的持久化开发工作和整合 ORM 技术，结束现在 Hibernate，TopLink，JDO 等 ORM 框架各自为营的局面。值得注意的是，JPA 是在充分吸收了现有 Hibernate，TopLink，JDO 等ORM框架的基础上发展而来的，具有易于使用，伸缩性强等优点。从目前的开发社区的反应上看，JPA 受到了极大的支持和赞扬，其中就包括了 Spring 与 EJB3.0 的开发团队
JPA所维护的核心是实体（Entity Bean），而它是通过一个持久化上下文（Persistence Context）来使用的。持久化上下文包含了以前3个部分：
对象关系映射（Object Relational Mapping，简称ORM）描述，JPA支持注解或XML两种形式的描述。 实体操作API，内置通用CRUD操作，来完成对象的持久化与查询。 查询语言，约定了面向对象的查询语句JPQL。 简单来说，JPA就是一种接口规范，一种定义了对象关系映射（ORM）以及实体对象的持久化接口标准的规范，并不是一套直接可用的产品（如：Hibernate）。
2、什么是Spring Data JPA spring-data-jpa：Spring Data JPA是Spring Data系列的一个组成部分，可以轻松快捷的实现数据访问层的增强支持，这使得基于Spring且使用了数据库访问技术的应用程序更加容易构建。 Spring Data JPA 内置了简单数据库读写操作，包括分页查询，并提供接口以待增强。</description>
    </item>
  </channel>
</rss>
